{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c45db7-f7e7-4c5e-a842-20e436ecb072",
   "metadata": {},
   "source": [
    "# Recommender Systems Code\n",
    "Author: Juho Hotari\n",
    "\n",
    "Here we test KNN, Popularity and Randomized algorithms and evaluate the performance based on the NDCG@5 value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd0821-1d9c-4bf8-a363-745eeacdd8e9",
   "metadata": {},
   "source": [
    "## Task 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9873555a-13e9-4922-b3e0-98db7ee03c78",
   "metadata": {},
   "source": [
    "### KNN User-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9aa739e-49de-4953-9f4a-d702fcb833c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a69b8ff-4889-447d-b7b5-66943bf5d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedKNNRecommender:\n",
    "    def __init__(self, k_neighbors=5):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.user_item_matrix = None\n",
    "        self.user_item_matrix_scaled = None\n",
    "        self.user_similarity_matrix = None\n",
    "        self.nearest_neighbors_model = None\n",
    "\n",
    "    def fit(self, train_file_path):\n",
    "        # Load training data\n",
    "        train_data = pd.read_csv(train_file_path)\n",
    "\n",
    "        # Create user-item matrix\n",
    "        self.user_item_matrix = train_data.pivot_table(index='user_id', columns='item_id', values='rating')\n",
    "\n",
    "        # Fill missing values with 0\n",
    "        self.user_item_matrix = self.user_item_matrix.fillna(0)\n",
    "\n",
    "        # Transpose user-item matrix to get item-user matrix\n",
    "        self.item_user_matrix = self.user_item_matrix.T\n",
    "\n",
    "        # Normalize the data\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        self.user_item_matrix_scaled = min_max_scaler.fit_transform(self.user_item_matrix)\n",
    "\n",
    "        # Compute cosine similarity between users\n",
    "        self.user_similarity_matrix = cosine_similarity(self.user_item_matrix_scaled)\n",
    "\n",
    "        # Fit Nearest Neighbors model\n",
    "        self.nearest_neighbors_model = NearestNeighbors(n_neighbors=self.k_neighbors, metric='cosine', algorithm='brute')\n",
    "        self.nearest_neighbors_model.fit(self.user_item_matrix_scaled)\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return 0\n",
    "\n",
    "        user_index = self.user_item_matrix.index.get_loc(user_id)\n",
    "\n",
    "        # Find k-nearest neighbors\n",
    "        _, indices = self.nearest_neighbors_model.kneighbors([self.user_item_matrix_scaled[user_index]], n_neighbors=self.k_neighbors)\n",
    "\n",
    "        # Predict rating based on weighted sum of ratings from neighbors\n",
    "        weighted_sum = 0\n",
    "        similarity_sum = 0\n",
    "        for neighbor_index in indices[0]:\n",
    "            if neighbor_index < self.user_item_matrix_scaled.shape[0]:\n",
    "                similarity = self.user_similarity_matrix[user_index][neighbor_index]\n",
    "                rating = self.user_item_matrix.iloc[neighbor_index][item_id]\n",
    "                weighted_sum += similarity * rating\n",
    "                similarity_sum += abs(similarity)\n",
    "\n",
    "        if similarity_sum == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            predicted_rating = weighted_sum / similarity_sum\n",
    "            return predicted_rating\n",
    "\n",
    "    def evaluate_ndcg(self, test_data, k=5, negative_samples=100):\n",
    "        ndcg_sum = 0\n",
    "        common_users = set(test_data['user_id']).intersection(set(self.user_item_matrix.index))\n",
    "    \n",
    "        for user_id in common_users:\n",
    "            try:\n",
    "                group = test_data[test_data['user_id'] == user_id]\n",
    "    \n",
    "                # Select the top k true ratings\n",
    "                true_ratings = group.sort_values(by='rating', ascending=False).head(k)['rating'].values\n",
    "    \n",
    "                # Predict ratings for all items in the group\n",
    "                predicted_ratings = [self.predict(user_id, item_id) for item_id in group['item_id'].values]\n",
    "    \n",
    "                # Uniformly sample negative examples\n",
    "                negative_samples_indices = np.random.choice(self.user_item_matrix.columns, size=negative_samples, replace=False)\n",
    "                negative_samples_ratings = [self.predict(user_id, item_id) for item_id in negative_samples_indices]\n",
    "    \n",
    "                # Combine true ratings and predicted ratings (including negative samples)\n",
    "                predicted_ratings = np.concatenate([predicted_ratings, negative_samples_ratings])\n",
    "    \n",
    "                # Sort the predicted ratings in descending order\n",
    "                predicted_ranking = np.argsort(predicted_ratings)[::-1][:min(k, len(predicted_ratings))]\n",
    "    \n",
    "                # Calculate DCG and IDCG\n",
    "                # Calculate DCG\n",
    "                dcg = np.sum((2 ** true_ratings - 1) / np.log2(2 + np.arange(1, min(k, len(true_ratings)) + 1)))\n",
    "\n",
    "                # Calculate IDCG\n",
    "                sorted_true_ratings = np.sort(true_ratings)[::-1]\n",
    "                idcg = np.sum((2 ** sorted_true_ratings - 1) / np.log2(2 + np.arange(1, min(k, len(true_ratings)) + 1)))\n",
    "\n",
    "    \n",
    "                # Update NDCG sum\n",
    "                ndcg_sum += dcg / idcg\n",
    "            except KeyError:\n",
    "                continue\n",
    "    \n",
    "        # Calculate the average NDCG over all users\n",
    "        average_ndcg = ndcg_sum / len(common_users)\n",
    "        return average_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbb86f-8531-4b07-a37e-c110b5184370",
   "metadata": {},
   "source": [
    "### k=5 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c71870-6c1c-4d8c-97b2-ca4fc8c115bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5: 0.8340807174887892\n",
      "CPU times: user 40min 27s, sys: 2h 1min 40s, total: 2h 42min 7s\n",
      "Wall time: 16min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate the recommender\n",
    "recommender = UserBasedKNNRecommender(k_neighbors=5)\n",
    "\n",
    "# Train the recommender on the training data\n",
    "recommender.fit('train.csv')\n",
    "\n",
    "# Evaluate performance on test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "ndcg_at_5 = recommender.evaluate_ndcg(test_data, k=5)\n",
    "\n",
    "print(f\"NDCG@5: {ndcg_at_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8423b9-628b-4d2b-a854-c11128ababf5",
   "metadata": {},
   "source": [
    "### k=3 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee7544a-07a0-40be-9290-d301aac83224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5: 0.8389261744966443\n",
      "CPU times: user 41min 4s, sys: 2h 3min 17s, total: 2h 44min 21s\n",
      "Wall time: 16min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate the recommender\n",
    "recommender = UserBasedKNNRecommender(k_neighbors=3)\n",
    "\n",
    "# Train the recommender on the training data\n",
    "recommender.fit('train.csv')\n",
    "\n",
    "# Evaluate performance on validation data\n",
    "test_data = pd.read_csv('validation.csv')\n",
    "ndcg_at_5 = recommender.evaluate_ndcg(test_data, k=5)\n",
    "\n",
    "print(f\"NDCG@5: {ndcg_at_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150189d5-fd03-40a4-af2b-07f529c5296e",
   "metadata": {},
   "source": [
    "### k=4 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ded59d-1e0a-4fab-b275-dca48663f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5: 0.8389261744966443\n",
      "CPU times: user 41min 31s, sys: 2h 5min 13s, total: 2h 46min 45s\n",
      "Wall time: 16min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate the recommender\n",
    "recommender = UserBasedKNNRecommender(k_neighbors=4)\n",
    "\n",
    "# Train the recommender on the training data\n",
    "recommender.fit('train.csv')\n",
    "\n",
    "# Evaluate performance on validation data\n",
    "test_data = pd.read_csv('validation.csv')\n",
    "ndcg_at_5 = recommender.evaluate_ndcg(test_data, k=5)\n",
    "\n",
    "print(f\"NDCG@5: {ndcg_at_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00964ba8-6ec5-4968-b7a9-25931a71864c",
   "metadata": {},
   "source": [
    "### Popularity algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445093a0-a65c-4020-afbe-d5dfa86d7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class PopularityAlgorithm:\n",
    "    def __init__(self, train_dataset):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.item_popularity = self.calculate_item_popularity()\n",
    "\n",
    "    def calculate_item_popularity(self):\n",
    "        item_popularity = self.train_dataset['item_id'].value_counts().reset_index()\n",
    "        item_popularity.columns = ['item_id', 'popularity']\n",
    "        return item_popularity.sort_values(by='popularity', ascending=False)\n",
    "\n",
    "    def generate_negative_samples(self, user_id, test_items, n_samples=100):\n",
    "        all_items = set(self.train_dataset['item_id'].unique()) - set(test_items)\n",
    "        negative_samples = random.sample(all_items, n_samples)\n",
    "        return [(user_id, item, 0) for item in negative_samples]\n",
    "\n",
    "    def evaluate(self, test_dataset):\n",
    "        result_table = []\n",
    "\n",
    "        for user_id in test_dataset['user_id'].unique():\n",
    "            user_test_set = test_dataset[test_dataset['user_id'] == user_id]\n",
    "            test_items = user_test_set['item_id'].tolist()\n",
    "\n",
    "            # Generate negative samples\n",
    "            negative_samples = self.generate_negative_samples(user_id, test_items)\n",
    "\n",
    "            # Combine test items and negative samples\n",
    "            all_items = test_items + [item[1] for item in negative_samples]\n",
    "\n",
    "            # Calculate scores for all items\n",
    "            scores = self.calculate_scores(user_id, all_items)\n",
    "\n",
    "            # Create the result table\n",
    "            user_results = pd.DataFrame({\n",
    "                'user_id': [user_id] * len(all_items),\n",
    "                'item_id': all_items,\n",
    "                'rating': [user_test_set[user_test_set['item_id'] == item]['rating'].values[0] if item in test_items else 0 for item in all_items],\n",
    "                'score': scores\n",
    "            })\n",
    "\n",
    "            result_table.append(user_results)\n",
    "\n",
    "        return pd.concat(result_table, ignore_index=True)\n",
    "\n",
    "    def calculate_scores(self, user_id, items):\n",
    "        # Example: Using item popularity as scores\n",
    "        return [self.item_popularity[self.item_popularity['item_id'] == item]['popularity'].values[0] if item in self.item_popularity['item_id'].values else 0 for item in items]\n",
    "\n",
    "    def calculate_dcg(self, user_id, sorted_items, k):\n",
    "        return np.sum((2 ** sorted_items['rating'].values - 1) / np.log2(np.arange(2, k + 2)))\n",
    "\n",
    "    def calculate_idcg(self, user_id, sorted_items_true_rating, k):\n",
    "        return np.sum((2 ** sorted_items_true_rating['rating'].values - 1) / np.log2(np.arange(2, k + 2)))\n",
    "\n",
    "    def calculate_ndcg(self, result_table, k=5):\n",
    "        ndcg_scores = []\n",
    "\n",
    "        unique_users = result_table['user_id'].unique()\n",
    "\n",
    "        for user_id in unique_users:\n",
    "            user_results = result_table[result_table['user_id'] == user_id]\n",
    "\n",
    "            # Sort items by score in descending order (SORT BY SCORE)\n",
    "            sorted_items = user_results.sort_values(by='score', ascending=False).head(k)\n",
    "\n",
    "            # Calculate DCG\n",
    "            dcg = self.calculate_dcg(user_id, sorted_items, k)\n",
    "\n",
    "            # Sort items by true rating in descending order (SORT BY USER RATING)\n",
    "            sorted_items_true_rating = user_results.sort_values(by='rating', ascending=False).head(k)\n",
    "\n",
    "            # Calculate IDCG\n",
    "            idcg = self.calculate_idcg(user_id, sorted_items_true_rating, k)\n",
    "\n",
    "            # Calculate NDCG\n",
    "            if idcg > 0:\n",
    "                ndcg = dcg / idcg\n",
    "                ndcg_scores.append(ndcg)\n",
    "\n",
    "        # Calculate average NDCG\n",
    "        average_ndcg = np.mean(ndcg_scores)\n",
    "        return average_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25203aa3-f19b-44ab-8c96-3981c1cc7c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/hotariju/19431641/ipykernel_3625071/1050880985.py:17: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  negative_samples = random.sample(all_items, n_samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG@5 for Popularity Algorithm: 0.5485\n",
      "CPU times: user 22.8 s, sys: 10.4 ms, total: 22.8 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_set = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')\n",
    "\n",
    "# Create an instance of the PopularityAlgorithm class\n",
    "popularity_algorithm = PopularityAlgorithm(train_set)\n",
    "\n",
    "# Evaluate the Popularity algorithm on the test set\n",
    "result_table_popularity = popularity_algorithm.evaluate(test_set)\n",
    "\n",
    "# Calculate NDCG@5 for the Popularity algorithm\n",
    "ndcg_popularity = popularity_algorithm.calculate_ndcg(result_table_popularity, k=5)\n",
    "\n",
    "# Print the average NDCG@5 for the Popularity algorithm\n",
    "print(f\"Average NDCG@5 for Popularity Algorithm: {ndcg_popularity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70c808-e7b9-418a-b9c2-b64a2688d1a0",
   "metadata": {},
   "source": [
    "### Randomized algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e92df54e-0133-448c-80a0-d3a2af0533a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomizedAlgorithm:\n",
    "    def __init__(self, train_dataset):\n",
    "        self.train_dataset = train_dataset\n",
    "\n",
    "    def generate_negative_samples(self, user_id, test_items, n_samples=100):\n",
    "        all_items = set(self.train_dataset['item_id'].unique()) - set(test_items)\n",
    "        negative_samples = random.sample(all_items, n_samples)\n",
    "        return [(user_id, item, 0) for item in negative_samples]\n",
    "\n",
    "    def evaluate(self, test_dataset):\n",
    "        result_table = []\n",
    "\n",
    "        for user_id in test_dataset['user_id'].unique():\n",
    "            user_test_set = test_dataset[test_dataset['user_id'] == user_id]\n",
    "            test_items = user_test_set['item_id'].tolist()\n",
    "\n",
    "            # Generate negative samples\n",
    "            negative_samples = self.generate_negative_samples(user_id, test_items)\n",
    "\n",
    "            # Combine test items and negative samples\n",
    "            all_items = test_items + [item[1] for item in negative_samples]\n",
    "\n",
    "            # Calculate scores for all items\n",
    "            scores = self.calculate_scores(user_id, all_items)\n",
    "\n",
    "            # Create the result table\n",
    "            user_results = pd.DataFrame({\n",
    "                'user_id': [user_id] * len(all_items),\n",
    "                'item_id': all_items,\n",
    "                'rating': [user_test_set[user_test_set['item_id'] == item]['rating'].values[0] if item in test_items else 0 for item in all_items],\n",
    "                'score': scores\n",
    "            })\n",
    "\n",
    "            result_table.append(user_results)\n",
    "\n",
    "        return pd.concat(result_table, ignore_index=True)\n",
    "\n",
    "    def calculate_scores(self, user_id, items):\n",
    "        # Example: Using random scores\n",
    "        return np.random.rand(len(items))\n",
    "\n",
    "    def calculate_dcg(self, user_id, sorted_items, k):\n",
    "        return np.sum((2 ** sorted_items['rating'].values - 1) / np.log2(np.arange(2, k + 2)))\n",
    "\n",
    "    def calculate_idcg(self, user_id, sorted_items_true_rating, k):\n",
    "        return np.sum((2 ** sorted_items_true_rating['rating'].values - 1) / np.log2(np.arange(2, k + 2)))\n",
    "\n",
    "    def calculate_ndcg(self, result_table, k=5):\n",
    "        ndcg_scores = []\n",
    "\n",
    "        unique_users = result_table['user_id'].unique()\n",
    "\n",
    "        for user_id in unique_users:\n",
    "            user_results = result_table[result_table['user_id'] == user_id]\n",
    "\n",
    "            # Sort items by score in descending order (SORT BY SCORE)\n",
    "            sorted_items = user_results.sort_values(by='score', ascending=False).head(k)\n",
    "\n",
    "            # Calculate DCG\n",
    "            dcg = self.calculate_dcg(user_id, sorted_items, k)\n",
    "\n",
    "            # Sort items by true rating in descending order (SORT BY RATING)\n",
    "            sorted_items_true_rating = user_results.sort_values(by='rating', ascending=False).head(k)\n",
    "\n",
    "            # Calculate IDCG\n",
    "            idcg = self.calculate_idcg(user_id, sorted_items_true_rating, k)\n",
    "\n",
    "            # Calculate NDCG\n",
    "            if idcg > 0:\n",
    "                ndcg = dcg / idcg\n",
    "                ndcg_scores.append(ndcg)\n",
    "\n",
    "        # Calculate average NDCG\n",
    "        average_ndcg = np.mean(ndcg_scores)\n",
    "        return average_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f4aae05-1376-4a07-87c2-d7a6425d9598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/hotariju/19431641/ipykernel_3625071/3345828678.py:18: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  negative_samples = random.sample(all_items, n_samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG@5 for Randomized Algorithm: 0.1041\n",
      "CPU times: user 6.07 s, sys: 3.87 ms, total: 6.08 s\n",
      "Wall time: 6.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an instance of the RandomizedAlgorithm class\n",
    "randomized_algorithm = RandomizedAlgorithm(train_set)\n",
    "\n",
    "# Evaluate the Randomized algorithm on the test set\n",
    "result_table_randomized = randomized_algorithm.evaluate(test_set)\n",
    "\n",
    "# Calculate NDCG@5 for the Randomized algorithm\n",
    "ndcg_randomized = randomized_algorithm.calculate_ndcg(result_table_randomized, k=5)\n",
    "\n",
    "# Print the average NDCG@5 for the Randomized algorithm\n",
    "print(f\"Average NDCG@5 for Randomized Algorithm: {ndcg_randomized:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91172467-c00a-4e7b-9f66-3f324d441558",
   "metadata": {},
   "source": [
    "## Task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c8cb2-c2d2-4448-9da6-efeaa46185bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset and metadata\n",
    "data = pd.read_csv('ratings.csv')  \n",
    "metadata = pd.read_csv('metadata.csv')   \n",
    "\n",
    "# Pick a random user\n",
    "random_user = np.random.choice(data['user_id'].unique())\n",
    "\n",
    "# Get the movies watched by the random user\n",
    "movies_watched = data[data['user_id'] == random_user]['item_id']\n",
    "\n",
    "# Get recommendations for the user using kNN collaborative filtering\n",
    "recommendations = []\n",
    "for item_id in data['item_id'].unique():\n",
    "    # Check if the user has not watched the movie\n",
    "    if item_id not in movies_watched.values:\n",
    "        # Predict the rating for the movie\n",
    "        predicted_rating = recommender.predict(random_user, item_id)\n",
    "        recommendations.append((item_id, predicted_rating))\n",
    "\n",
    "# Sort recommendations by predicted rating in descending order\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 5 recommendations with movie titles\n",
    "print(f\"User {random_user} - Movies Watched:\")\n",
    "for movie_id in movies_watched.values:\n",
    "    movie_title = metadata[metadata['item_id'] == movie_id]['title'].values\n",
    "    if len(movie_title) > 0:\n",
    "        print(f\"- {movie_title[0]}\")\n",
    "    else:\n",
    "        print(f\"- Movie {movie_id} (Title not found in metadata)\")\n",
    "\n",
    "print(\"\\nTop 5 Recommendations:\")\n",
    "for i, (item_id, predicted_rating) in enumerate(recommendations[:5], 1):\n",
    "    movie_title = metadata[metadata['item_id'] == item_id]['title'].values\n",
    "    if len(movie_title) > 0:\n",
    "        print(f\"{i}. {movie_title[0]} - Predicted Rating: {predicted_rating}\")\n",
    "    else:\n",
    "        print(f\"{i}. Movie {item_id} (Title not found in metadata) - Predicted Rating: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb9e93-f0ee-41bb-972c-e448bb4eb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a few users for demonstration\n",
    "selected_users = ratings['user_id'].sample(3).values\n",
    "\n",
    "# Prepare user-item matrix for kNN collaborative filtering\n",
    "user_item_matrix = ratings.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)\n",
    "\n",
    "# Fit kNN model\n",
    "recommender = UserBasedKNNRecommender(k_neighbors=4)\n",
    "\n",
    "# Train the recommender on the training data\n",
    "recommender.fit('train.csv')\n",
    "\n",
    "# Display top similar users for each selected user\n",
    "for user_id in selected_users:\n",
    "    user_index = user_item_matrix.index.get_loc(user_id)\n",
    "    \n",
    "    # Find top similar users\n",
    "    similar_users = recommender.kneighbors(user_item_matrix.iloc[user_index, :].values.reshape(1, -1), n_neighbors=5 + 1, return_distance=False)[0][1:]\n",
    "    \n",
    "    print(f\"\\nTop 5 Similar Users for User {user_id}:\")\n",
    "    print(user_item_matrix.index[similar_users])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
